@misc{kuangliu,
  title = {Train {CIFAR-10} with {PyTorch}},
  howpublished = {\url{https://github.com/kuangliu/pytorch-cifar}},
  year={2017},
  author={Kuang Liu}
}

@article{Demirkaya2020ExploringTR,
  title={Exploring the Role of Loss Functions in Multiclass Classification},
  author={Ahmet Demirkaya and Jiasi Chen and Samet Oymak},
  journal={Conference on Information Sciences and Systems},
  year={2020}
}

@inproceedings{deng2009imagenet,
  title={{ImageNet}: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={Computer Vision and Pattern Recognition},
  year={2009}
}

@TECHREPORT{Krizhevsky09learningmultiple,
    author = {Alex Krizhevsky},
    title = {Learning multiple layers of features from tiny images},
    institution = {University of Toronto},
    type={Technical report},
    year = {2009}
}

@article{He2015DeepRL,
  title={Deep Residual Learning for Image Recognition},
  author={Kaiming He and X. Zhang and Shaoqing Ren and Jian Sun},
  journal={Computer Vision and Pattern Recognition},
  year={2015}
}

@inproceedings{simonyan2015a,
  booktitle = {International Conference on Learning Representations},
  title = {Very deep convolutional networks for large-scale image recognition},
  author = {Karen Simonyan and Andrew Zisserman},
  year = {2015}
}


@misc{tutorial,
  author = {Francesco Orabona and Ashok Cutkosky},
  title = {{ICML} 2020 Tutorial on Parameter-Free Online Optimization},
  year = {2020}
}

@article{LIU202285,
title = {Loss landscapes and optimization in over-parameterized non-linear systems and neural networks},
journal = {Applied and Computational Harmonic Analysis},
year = {2022},
author = {Chaoyue Liu and Libin Zhu and Mikhail Belkin}
}

@article {Loewenstein9481,
	author = {Loewenstein, Yonatan and Kuras, Annerose and Rumpel, Simon},
	title = {Multiplicative Dynamics Underlie the Emergence of the Log-Normal Distribution of Spine Sizes in the Neocortex In Vivo},
	year = {2011},
	journal = {Journal of Neuroscience}
}

@phdthesis{bernstein-thesis,
  author  = {Jeremy Bernstein},
  title   = {Optimisation \& Generalisation in Networks of Neurons},
  school  = {California Institute of Technology},
  year    = 2022,
  type    = {{Ph.D.} thesis}
}

@article{bregman,
author = {Dhillon, Inderjit S. and Tropp, Joel A.},
title = {Matrix Nearness Problems with {Bregman} Divergences},
journal = {SIAM Journal on Matrix Analysis and Applications},
year = {2008}
}

@inproceedings{deeprlmatters,
author = {Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
title = {Deep Reinforcement Learning That Matters},
year = {2018},
booktitle = {AAAI Conference on Artificial Intelligence}
}

@inproceedings{Lucic2017AreGC,
  title={Are {GANs} Created Equal? {A} Large-Scale Study},
  author={Mario Lucic and Karol Kurach and Marcin Michalski and Sylvain Gelly and Olivier Bousquet},
  booktitle={Neural Information Processing Systems},
  year={2017}
}

@article{Li2018OnTC,
  title={On the Convergence of Stochastic Gradient Descent with Adaptive Stepsizes},
  author={Xiaoyun Li and Francesco Orabona},
  journal={ArXiv},
  year={2018},
  volume={abs/1805.08114}
}

@inproceedings{
Zhang2020Why,
title={Why Gradient Clipping Accelerates Training: A Theoretical Justification for Adaptivity},
author={Jingzhao Zhang and Tianxing He and Suvrit Sra and Ali Jadbabaie},
booktitle={International Conference on Learning Representations},
year={2020}
}

@article{Agarwal2016FindingAL,
  title={Finding approximate local minima faster than gradient descent},
  author={Naman Agarwal and Zeyuan Allen Zhu and Brian Bullins and Elad Hazan and Tengyu Ma},
  journal={Symposium on Theory of Computing},
  year={2016}
}

@inproceedings{Yang2021TensorPI,
  title={Tensor Programs {IV}: Feature Learning in Infinite-Width Neural Networks},
  author={Greg Yang and Edward J. Hu},
  booktitle={International Conference on Machine Learning},
  year={2021}
}

@book{Nocedal1999NumericalO,
  title={Numerical Optimization},
  author={Jorge Nocedal and Stephen J. Wright},
  publisher={Springer},
  year={1999}
}

@article{Rumelhart1986LearningRB,
  title={Learning representations by back-propagating errors},
  author={David E. Rumelhart and Geoffrey E. Hinton and Ronald J. Williams},
  journal={Nature},
  year={1986}
}

@InProceedings{pmlr-v28-schaul13,
  title = 	 {No more pesky learning rates},
  author = 	 {Schaul, Tom and Zhang, Sixin and LeCun, Yann},
  booktitle = 	 {Proceedings of the 30th International Conference on Machine Learning},
  pages = 	 {343--351},
  year = 	 {2013},
  editor = 	 {Dasgupta, Sanjoy and McAllester, David},
  volume = 	 {28},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Atlanta, Georgia, USA},
  month = 	 {17--19 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v28/schaul13.pdf},
  url = 	 {https://proceedings.mlr.press/v28/schaul13.html},
  abstract = 	 {The performance of stochastic gradient descent (SGD) depends critically on how learning rates are tuned and decreased over time. We propose a method to automatically adjust multiple learning rates so as to minimize the expected error at any one time. The method relies on local gradient variations across samples. In our approach, learning rates can increase as well as decrease, making it suitable for non-stationary problems. Using a number of convex and non-convex learning tasks, we show that the resulting algorithm matches the performance of the best settings obtained through systematic search, and effectively removes the need for learning rate tuning.}
}


@book{Kato:1966:PTL,
  added-at = {2006-05-12T17:24:33.000+0200},
  alias = {Kato 66},
  author = {Kato, Tosio},
  bibdate = {Fri Nov 24 15:18:30 1995},
  bibsource = {ftp://ftp.math.utah.edu/pub/bibnet/authors/m/matched-field-proc.bib},
  biburl = {https://www.bibsonomy.org/bibtex/2ee37aa5451e22c2ba157c4d96a0247c3/schmitz},
  interhash = {d24d6bf8b4fedd55af886b5f6724a5fa},
  intrahash = {ee37aa5451e22c2ba157c4d96a0247c3},
  key = {eigenvalues, hilbert spaces},
  keywords = {perturbation spectral eigenvalue eigenvector analysis},
  lccn = {QA320 .K33},
  pages = {xix + 592},
  sthbib = {M3 Kat 81 60},
  timestamp = {2006-05-12T17:24:33.000+0200},
  title = {Perturbation Theory for Linear Operators},
  year = 1966,
  publisher = {Springer}
}

@article{Weyl1912,
author = {Hermann Weyl},
journal = {Mathematische Annalen},
title = {Das asymptotische {V}erteilungsgesetz der {E}igenwerte linearer partieller {D}ifferentialgleichungen (mit einer {A}nwendung auf die {T}heorie der {H}ohlraumstrahlung)},
year = {1912}
}

@article{STEWART200653,
title = "Perturbation of the {SVD} in the presence of small singular values",
journal = "Linear Algebra and its Applications",
year = "2006",
author = "Michael Stewart"
}

@article{hessian-linear,
author = {Agarwal, Naman and Bullins, Brian and Hazan, Elad},
title = {Second-Order Stochastic Optimization for Machine Learning in Linear Time},
year = {2017},
journal = {Journal of Machine Learning Research}
}

@article{bottou,
author = {Bottou, L\'{e}on and Curtis, Frank E. and Nocedal, Jorge},
title = {Optimization Methods for Large-Scale Machine Learning},
journal = {SIAM Review},
year = {2018}
}

@techreport{Radford2019LanguageMA,
  title={Language Models are Unsupervised Multitask Learners},
  author={Alec Radford and Jeff Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
  institution = {OpenAI},
    type={Technical report},
  year={2019}
}

@article{Kaplan2020ScalingLF,
  title={Scaling Laws for Neural Language Models},
  author={Jared Kaplan and Sam McCandlish and T. J. Henighan and Tom B. Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeff Wu and Dario Amodei},
  journal={arXiv:2001.08361},
  year={2020}
}

@inproceedings{hammerstrom,
  author={Tom {Baker} and Dan {Hammerstrom}},
  booktitle={International Symposium on Circuits and Systems}, 
  title={Characterization of artificial neural network algorithms}, 
  year={1989}}

@article{Sharir2020TheCO,
  title={The Cost of Training {NLP} Models: A Concise Overview},
  author={Or Sharir and Barak Peleg and Yoav Shoham},
  journal={arXiv:2004.08900},
  year={2020}
}

@article{tieleman_rmsprop_2012,
	title = {{RMSprop}},
	volume = {Lecture 6.5},
	journal = {Coursera: Neural Networks for Machine Learning},
	author = {Tieleman, Tijmen and Hinton, Geoffrey},
	year = {2012}
}

@ARTICLE{Theano,
   author = {
     Rami Al-Rfou and
     Guillaume Alain and
     Amjad Almahairi and
     Christof Angermueller and
     Dzmitry Bahdanau and
     Nicolas Ballas and
     Fr\'ed\'eric Bastien and
     Justin Bayer and
     Anatoly Belikov and
     Alexander Belopolsky and
     Yoshua Bengio and
     Arnaud Bergeron and
     James Bergstra and
     Valentin Bisson and
     Josh {Bleecher Snyder} and
     Nicolas Bouchard and
     Nicolas Boulanger-Lewandowski and
     Xavier Bouthillier and
     Alexandre de Br\'ebisson and
     Olivier Breuleux and
     Pierre-Luc Carrier and
     Kyunghyun Cho and
     Jan Chorowski and
     Paul Christiano and
     Tim Cooijmans and
     Marc-Alexandre C\^ot\'e and
     Myriam C\^ot\'e and
     Aaron Courville and
     Yann N. Dauphin and
     Olivier Delalleau and
     Julien Demouth and
     Guillaume Desjardins and
     Sander Dieleman and
     Laurent Dinh and
     M\'elanie Ducoffe and
     Vincent Dumoulin and
     Samira {Ebrahimi Kahou} and
     Dumitru Erhan and
     Ziye Fan and
     Orhan Firat and
     Mathieu Germain and
     Xavier Glorot and
     Ian Goodfellow and
     Matt Graham and
     Caglar Gulcehre and
     Philippe Hamel and
     Iban Harlouchet and
     Jean-Philippe Heng and
     Bal\'azs Hidasi and
     Sina Honari and
     Arjun Jain and
     S\'ebastien Jean and
     Kai Jia and
     Mikhail Korobov and
     Vivek Kulkarni and
     Alex Lamb and
     Pascal Lamblin and
     Eric Larsen and
     C\'esar Laurent and
     Sean Lee and
     Simon Lefrancois and
     Simon Lemieux and
     Nicholas L\'eonard and
     Zhouhan Lin and
     Jesse A. Livezey and
     Cory Lorenz and
     Jeremiah Lowin and
     Qianli Ma and
     Pierre-Antoine Manzagol and
     Olivier Mastropietro and
     Robert T. McGibbon and
     Roland Memisevic and
     Bart van Merri\"enboer and
     Vincent Michalski and
     Mehdi Mirza and
     Alberto Orlandi and
     Christopher Pal and
     Razvan Pascanu and
     Mohammad Pezeshki and
     Colin Raffel and
     Daniel Renshaw and
     Matthew Rocklin and
     Adriana Romero and
     Markus Roth and
     Peter Sadowski and
     John Salvatier and
     Fran\c{c}ois Savard and
     Jan Schl\"uter and
     John Schulman and
     Gabriel Schwartz and
     Iulian Vlad Serban and
     Dmitriy Serdyuk and
     Samira Shabanian and
     \'Etienne Simon and
     Sigurd Spieckermann and
     S. Ramana Subramanyam and
     Jakub Sygnowski and
     J\'er\'emie Tanguay and
     Gijs van Tulder and
     Joseph Turian and
     Sebastian Urban and
     Pascal Vincent and
     Francesco Visin and
     Harm de Vries and
     David Warde-Farley and
     Dustin J. Webb and
     Matthew Willson and
     Kelvin Xu and
     Lijun Xue and
     Li Yao and
     Saizheng Zhang and
     Ying Zhang},
 collaboration = {Theano Development Team},
    title = "{Theano: A {Python} framework for fast computation of mathematical expressions}",
  journal = {arXiv:1605.02688},
     year = 2016
}


@inproceedings{pytorch,
title = {{PyTorch}: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Neural Information Processing Systems},
year = {2019}
}

@article{Philipp2017TheEG,
  title={The exploding gradient problem demystified},
  author={George Philipp and Dawn Xiaodong Song and Jaime G. Carbonell},
  journal={arXiv:1712.05577},
  year={2017}
}

@article{Saxe2013ExactST,
  title={Exact solutions to the nonlinear dynamics of learning in deep linear neural networks},
  author={Andrew M. Saxe and James L. McClelland and Surya Ganguli},
  journal={CoRR},
  year={2013},
  volume={abs/1312.6120}
}

@book{mackay,
  author = {MacKay, David J. C.},
  title = {Information Theory, Inference, and Learning Algorithms},
  year = {2003},
  publisher = {Cambridge University Press}
}

@InProceedings{pmlr-v139-brock21a,
  title = 	 {High-Performance Large-Scale Image Recognition Without Normalization},
  author = {Brock, Andy and De, Soham and Smith, Samuel L. and Simonyan, Karen},
  booktitle = {International Conference on Machine Learning},
  year = 	 {2021}
}


@inproceedings{
carbonnelle2019layer,
title={Layer rotation: {A} surprisingly simple indicator of generalization in deep networks?},
author={Simon Carbonnelle and Christophe De Vleeschouwer},
booktitle={ICML Workshop on Identifying and Understanding Deep Learning Phenomena},
year={2019}
}

@techreport{You:EECS-2017-156,
    Author = {You, Yang and Gitman, Igor and Ginsburg, Boris},
    Title = {Scaling {SGD} batch size to 32{K} for {I}mage{N}et training},
    Year = {2017},
    Institution = {University of California, Berkeley},
    type={Technical report}
}

@inproceedings{
yang2021tuning,
title={Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer},
author={Greg Yang and Edward J. Hu and Igor Babuschkin and Szymon Sidor and Xiaodong Liu and David Farhi and Nick Ryder and Jakub Pachocki and Weizhu Chen and Jianfeng Gao},
booktitle={Neural Information Processing Systems},
year={2021}
}

@inproceedings{
cohen2021gradient,
title={Gradient Descent on Neural Networks Typically Occurs at the Edge of Stability},
author={Jeremy Cohen and Simran Kaur and Yuanzhi Li and J. Zico Kolter and Ameet Talwalkar},
booktitle={International Conference on Learning Representations},
year={2021}
}

@inproceedings{revisiting-ngd,
  author    = {Razvan Pascanu and
               Yoshua Bengio},
  title     = {Revisiting Natural Gradient for Deep Networks},
  booktitle = {International Conference on Learning Representations},
  year      = {2014}
}

@book{gauss-newton,
author = {Björck, Åke},
title = {Numerical Methods for Least Squares Problems},
publisher = {Society for Industrial and Applied Mathematics},
year = {1996}
}


@book{info-geom,
author = {Amari, Shun-ichi},
title = {Information Geometry and Its Applications},
year = {2016},
publisher = {Springer},
}

@article{Nesterov2006CubicRO,
  title={Cubic regularization of {N}ewton method and its global performance},
  author={Yurii Nesterov and Boris Polyak},
  journal={Mathematical Programming},
  year={2006}
}

@book{nemirovsky_yudin_1983, place={Chichester}, title={Problem complexity and method efficiency in optimization}, publisher={Wiley}, author={Nemirovsky, Arkady S. and Yudin, David B.}, year={1983}}

@article{scaling-laws,
  title={Scaling Laws for Neural Language Models},
  author={Jared Kaplan and Sam McCandlish and Tom Henighan and Tom B. Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeffrey Wu and Dario Amodei},
  journal={arXiv:2001.08361},
  year={2020}
}

@inproceedings{relu,
author = {Nair, Vinod and Hinton, Geoffrey E.},
title = {Rectified Linear Units Improve Restricted {B}oltzmann Machines},
year = {2010},
booktitle = {International Conference on Machine Learning}
}

@book{lwk,
author = {Schölkopf, Bernhard and Smola, Alexander J.},
title = {Learning with Kernels: {S}upport Vector Machines, Regularization, Optimization, and Beyond},
year = {2001},
publisher = {MIT Press}
}

@book{mm,
author = {Lange, Kenneth},
title = {{MM} Optimization Algorithms},
publisher = {Society for Industrial and Applied Mathematics},
year = {2016}
}


@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    year={2016}
}

@inproceedings{NIPS2017_9ef2ed4b,
 author = {Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
 booktitle = {Neural Information Processing Systems},
 title = {Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles},
 year = {2017}
}



@book{gpml,
author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
title = {Gaussian Processes for Machine Learning},
year = {2005},
publisher = {MIT Press}
}

@inproceedings{rivasplataKSS20,
  author={Omar Rivasplata and Ilja Kuzborskij and Csaba Szepesvári and John Shawe-Taylor},
  title={{PAC-B}ayes Analysis Beyond the Usual Bounds},
  year={2020},
  booktitle={Neural Information Processing Systems}
}

@inproceedings{
Nakkiran2020Deep,
title={Deep Double Descent: {W}here Bigger Models and More Data Hurt},
author={Preetum Nakkiran and Gal Kaplun and Yamini Bansal and Tristan Yang and Boaz Barak and Ilya Sutskever},
booktitle={International Conference on Learning Representations},
year={2020}
}

@inproceedings{choandsaul,
 author = {Cho, Youngmin and Saul, Lawrence K.},
 booktitle = {Neural Information Processing Systems},
 title = {Kernel Methods for Deep Learning},
 year = {2009}
}

@inproceedings{daniely,
 author = {Daniely, Amit and Frostig, Roy and Singer, Yoram},
 booktitle = {Neural Information Processing Systems},
 title = {Toward Deeper Understanding of Neural Networks: The Power of Initialization and a Dual View on Expressivity},
 year = {2016}
}

@phdthesis{nakkiran,
  author       = {Preetum Nakkiran}, 
  title        = {Towards an Empirical Theory of Deep Learning},
  school       = {Department of Computer Science, Harvard University},
  year         = 2021,
  type     = {{Ph.D.} thesis}
}

@inproceedings{Keskar2017OnLT,
  title={On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima},
  author={Nitish Shirish Keskar and Dheevatsa Mudigere and Jorge Nocedal and Mikhail Smelyanskiy and Ping Tak Peter Tang},
  booktitle = {International Conference on Learning Representations},
  year={2017}
}

@inproceedings{Wu2017TowardsUG,
  title={Towards Understanding Generalization of Deep Learning: Perspective of Loss Landscapes},
  author={Lei Wu and Zhanxing Zhu and E Weinan},
  booktitle={ICML Workshop on Principled Approaches to Deep Learning},
  year={2017}
}

@inproceedings{NEURIPS2018_a41b3bb3,
 author = {Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
 booktitle = {Neural Information Processing Systems},
 title = {Visualizing the Loss Landscape of Neural Nets},
 year = {2018}
}


@inproceedings{bartlett,
 author = {Bartlett, Peter L. and Foster, Dylan J. and Telgarsky, Matus J.},
 booktitle = {Neural Information Processing Systems},
 title = {Spectrally-normalized margin bounds for neural networks},
 year = {2017}
}

@inproceedings{extremeMemorization,
 author = {Mehta, Harsh and Cutkosky, Ashok and Neyshabur, Behnam},
 booktitle = {International Conference on Learning Representations},
 title = {Extreme Memorization via Scale of Initialization},
 year = {2021}
 }
 
 @inproceedings{balakrishnanFace,
 author = {Balakrishnan, Guha and Xiong, Yuanjun and Xia, Wei and Perona, Pietro},
 booktitle = {European Conference on Computer Vision},
 title = {Towards causal benchmarking of bias in face analysis algorithms},
 year = {2020}
 }

 
 @inproceedings{HuiSquareCrossEntropy,
 author = {Like Hui and Mikhail Belkin},
 booktitle = {International Conference on Learning Representations},
 title = {Evaluation of Neural Architectures Trained with Square Loss vs.\ Cross-Entropy in Classification Tasks},
 year = {2021}
 }

@article{liu2021learning,
  title={Learning by turning: Neural architecture aware optimisation},
  author={Liu, Yang and Bernstein, Jeremy and Meister, Markus and Yue, Yisong},
  journal={arXiv preprint arXiv:2102.07227},
  year={2021}
}


@InProceedings{pmlr-v139-liu21c,
  title = 	 {Learning by Turning: Neural Architecture Aware Optimisation},
  author =       {Liu, Yang and Bernstein, Jeremy and Meister, Markus and Yue, Yisong},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2021}
}



@inproceedings{
jiang2019fantastic,
title={Fantastic Generalization Measures and Where to Find Them},
author={Yiding Jiang and Behnam Neyshabur and Hossein Mobahi and Dilip Krishnan and Samy Bengio},
booktitle={International Conference on Learning Representations},
year={2020}
}

@inproceedings{dziugaite2020search,
  author={Gintare Karolina Dziugaite and Alexandre Drouin and Brady Neal and Nitarshan Rajkumar and Ethan Caballero and Linbo Wang and Ioannis Mitliagkas and Daniel M. Roy},
  title={In search of robust measures of generalization},
  year={2020},
  booktitle={Neural Information Processing Systems}
}

@article{mcallester1999some,
  title={Some {PAC-B}ayesian theorems},
  author={McAllester, David A},
  journal={Machine Learning},
  year={1999}
}

@inproceedings{arora2019fine,
  title={Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks},
  author={Arora, Sanjeev and Du, Simon and Hu, Wei and Li, Zhiyuan and Wang, Ruosong},
  booktitle={International Conference on Machine Learning},
  pages={322--332},
  year={2019},
  organization={PMLR}
}

@article{cao2019generalization,
  title={Generalization bounds of stochastic gradient descent for wide and deep neural networks},
  author={Cao, Yuan and Gu, Quanquan},
  journal={Neural Information Processing Systems},
  year={2019}
}

@article{franklin2005elements,
  title={The elements of statistical learning: data mining, inference and prediction},
  author={Franklin, James},
  journal={The Mathematical Intelligencer},
  volume={27},
  number={2},
  pages={83--85},
  year={2005},
  publisher={Springer}
}

@inproceedings{boser_guyon_vapnik, 
author = {Boser, Bernhard E. and Guyon, Isabelle M. and Vapnik, Vladimir N.}, 
title = {A Training Algorithm for Optimal Margin Classifiers}, 
year = {1992}, 
booktitle = {Workshop on Computational Learning Theory}
}

@article{cortes1995support,
  title={Support-vector networks},
  author={Cortes, Corinna and Vapnik, Vladimir},
  journal={Machine Learning},
  year={1995}
}

@inproceedings{rosset2003margin,
  title={Margin Maximizing Loss Functions},
  author={Rosset, Saharon and Zhu, Ji and Hastie, Trevor},
  booktitle={Neural Information Processing Systems},
  year={2003}
}

@book{vapnik1999nature,
  title={The Nature of Statistical Learning Theory},
  author={Vapnik, Vladimir},
  year={1999},
  publisher={Springer}
}

@inproceedings{elsayed2018large,
author = {Elsayed, Gamaleldin F. and Krishnan, Dilip and Mobahi, Hossein and Regan, Kevin and Bengio, Samy},
title = {Large Margin Deep Networks for Classification},
year = {2018},
booktitle = {Neural Information Processing Systems}
}

@article{zhang2021flatness,
      title={Why flatness does and does not correlate with generalization for deep neural networks}, 
      author={Shuofeng Zhang and Isaac Reid and Guillermo Valle Pérez and Ard Louis},
      year={2021},
      journal={arXiv:2103.06219}
}

@article{soudry2018implicit,
  title={The implicit bias of gradient descent on separable data},
  author={Soudry, Daniel and Hoffer, Elad and Nacson, Mor Shpigel and Gunasekar, Suriya and Srebro, Nathan},
  journal={Journal of Machine Learning Research},
  year={2018}
}

@article{neyshabur2017pac,
  title={A {PAC-B}ayesian approach to spectrally-normalized margin bounds for neural networks},
  author={Neyshabur, Behnam and Bhojanapalli, Srinadh and Srebro, Nathan},
  journal={International Conference on Learning Representations},
  year={2017}
}

@article{zhang2021understanding,
  title={Understanding deep learning (still) requires rethinking generalization},
  author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
  journal={Communications of the ACM},
  year={2021}
}

@inproceedings{nagarajan2019generalization,
  title={Generalization in deep networks: The role of distance from initialization},
  author={Nagarajan, Vaishnavh and Kolter, J. Zico},
  booktitle={NeurIPS Workshop on Deep Learning: Bridging Theory and Practice},
  year={2017}
}

@inproceedings{
jiang2018predicting,
title={Predicting the Generalization Gap in Deep Networks with Margin Distributions},
author={Yiding Jiang and Dilip Krishnan and Hossein Mobahi and Samy Bengio},
booktitle={International Conference on Learning Representations},
year={2019}
}

@inproceedings{NEURIPS2019_05e97c20,
 author = {Nagarajan, Vaishnavh and Kolter, J. Zico},
 booktitle = {Neural Information Processing Systems},
 title = {Uniform convergence may be unable to explain generalization in deep learning},
 year = {2019}
}
@inproceedings{danroy_nonvacuous,
        title = {Computing Nonvacuous Generalization Bounds for Deep (Stochastic) Neural Networks with Many More Parameters than Training Data},
       author = {Gintare Karolina Dziugaite and Daniel M. Roy},
         year = {2017},
    booktitle = {Uncertainty in Artificial Intelligence}
}

@article{langford2003pac,
  title={{PAC-B}ayes \& margins},
  author={Langford, John and Shawe-Taylor, John},
  journal={Neural Information Processing Systems},
  year={2003}
}

@inproceedings{neyshabur2015norm,
  title={Norm-based capacity control in neural networks},
  author={Neyshabur, Behnam and Tomioka, Ryota and Srebro, Nathan},
  booktitle={Conference on Learning Theory},
  year={2015}
}

% May need to edit this bibtex.  Are the following bibtex appropriate? They seem a bit more in depth
@InProceedings{woodworth20a,
  title = 	 {Kernel and Rich Regimes in Overparametrized Models},
  author =       {Woodworth, Blake and Gunasekar, Suriya and Lee, Jason D. and Moroshko, Edward and Savarese, Pedro and Golan, Itay and Soudry, Daniel and Srebro, Nathan},
  booktitle = 	 {Conference on Learning Theory},
  year = 	 {2020}
}

@article{Geiger_2020,
	year = 2020,
	author = {Mario Geiger and Stefano Spigler and Arthur Jacot and Matthieu Wyart},
	title = {Disentangling feature and lazy training in deep neural networks},
	journal = {Journal of Statistical Mechanics: Theory and Experiment}
}



@inproceedings{
valle_perez2018deep,
title={Deep learning generalizes because the parameter--function map is biased towards simple functions},
author={Guillermo Valle-Perez and Chico Q. Camargo and Ard A. Louis},
booktitle={International Conference on Learning Representations},
year={2019}
}

@article{mingard2021sgd,
  title={Is {SGD} a {B}ayesian sampler? {W}ell, almost},
  author={Mingard, Chris and Valle-P{\'e}rez, Guillermo and Skalse, Joar and Louis, Ard A},
  journal={Journal of Machine Learning Research},
  year={2021}
}

@article{de2019random,
  title={Random deep neural networks are biased towards simple functions},
  author={De Palma, Giacomo and Kiani, Bobak and Lloyd, Seth},
  journal={Neural Information Processing Systems},
  year={2019}
}


@inproceedings{NTKjacot,
	Author = {Jacot, Arthur and Gabriel, Franck and Hongler, Clement},
	Booktitle = {Neural Information Processing Systems},
	Title = {Neural Tangent Kernel: {C}onvergence and Generalization in Neural Networks},
	Year = {2018}
	}



%%%%%%%

@inproceedings{
azizan2018stochastic,
title={Stochastic Gradient/Mirror Descent: {M}inimax Optimality and Implicit Regularization},
author={Navid Azizan and Babak Hassibi},
booktitle={International Conference on Learning Representations},
year={2019}
}

@article{amari,
    author = {Amari, Shun-ichi},
    title = {Natural Gradient Works Efficiently in Learning},
    journal = {Neural Computation},
    year = {1998}
}

@article{SCHMIDHUBER201585,
title = {Deep learning in neural networks: {A}n overview},
journal = {Neural Networks},
year = {2015},
author = {Jürgen Schmidhuber}
}

@article{deeplearning,
author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey E.},
year = {2015},
title = {Deep Learning},
journal = {Nature}
}

@inproceedings{steinkrau,
author = {Steinkraus, Dave and Buck, Ian and Simard, Patrice Y.},
title = {Using {GPU}s for Machine Learning Algorithms},
year = {2005},
booktitle = {International Conference on Document Analysis and Recognition}
}

@article{Fukushima2004NeocognitronAS,
  title={Neocognitron: {A} self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position},
  author={Kunihiko Fukushima},
  journal={Biological Cybernetics},
  year={1980}
}

@book{Sutton1998,
  author = {Sutton, Richard S. and Barto, Andrew G.},
  publisher = {MIT Press},
  title = {Reinforcement Learning: An Introduction},
  year = {2018 }
}

@article{stability,
author = {Olivier Bousquet and André Elisseeff},
title = {Stability and Generalization},
year = {2002},
journal = {Journal of Machine Learning Research}
}

@inproceedings{kingma_adam:_2015,
	title = {Adam: {A} Method for Stochastic Optimization},
	shorttitle = {Adam},
	booktitle = {International Conference on Learning Representations},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	year = {2015}
}

@book{mackay,
  author = {MacKay, David J. C.},
  title = {Information Theory, Inference, and Learning Algorithms},
  year = {2003},
  publisher = {Cambridge University Press}
}

@inproceedings{crowded_valley,
  author={Robin M. Schmidt and Frank Schneider and Philipp Hennig},
  title={Descending through a Crowded Valley---Benchmarking Deep Learning Optimizers},
  year={2021},
  booktitle={International Conference on Machine Learning}
}

@inproceedings{
hui2021evaluation,
title={Evaluation of Neural Architectures Trained with Square Loss vs.\ Cross-Entropy in Classification Tasks},
author={Like Hui and Mikhail Belkin},
booktitle={International Conference on Learning Representations},
year={2021}
}

@inproceedings{why-svms-work,
 author = {Herbrich, Ralf and Graepel, Thore},
 booktitle = {Neural Information Processing Systems},
 title = {A {PAC-B}ayesian Margin Bound for Linear Classifiers: Why {SVM}s work},
 year = {2001}
}

@inproceedings{
zhang2018mixup,
title={mixup: Beyond Empirical Risk Minimization},
author={Hongyi Zhang and Moustapha Cisse and Yann N. Dauphin and David Lopez-Paz},
booktitle={International Conference on Learning Representations},
year={2018}
}

@inproceedings{label-smoothing,
author = {M\"{u}ller, Rafael and Kornblith, Simon and Hinton, Geoffrey},
title = {When Does Label Smoothing Help?},
year = {2019},
booktitle = {Neural Information Processing Systems}
}

@inproceedings{mobahi,
  title={Self-Distillation Amplifies Regularization
in {H}ilbert Space},
  author={Hossein Mobahi and Mehrdad Farajtabar and Peter L. Bartlett},
  booktitle={Neural Information Processing Systems},
  year={2020}
}

@inproceedings{Zhang2020SelfDistillationAI,
  title={Self-Distillation as Instance-Specific Label Smoothing},
  author={Zhilu Zhang and Mert Rory Sabuncu},
  booktitle={Neural Information Processing Systems},
  year={2020}
}

@inproceedings{Furlanello2018BornAN,
  title={Born Again Neural Networks},
  author={Tommaso Furlanello and Zachary Chase Lipton and Michael Tschannen and Laurent Itti and Anima Anandkumar},
  booktitle={International Conference on Machine Learning},
  year={2018}
}

@inproceedings{nagarajan,
author = {Nagarajan, Vaishnavh and Kolter, J. Zico},
title = {Uniform Convergence May Be Unable to Explain Generalization in Deep Learning},
year = {2019},
booktitle = {Neural Information Processing Systems}
}

@inproceedings{
smith2021on,
title={On the Origin of Implicit Regularization in Stochastic Gradient Descent},
author={Samuel L. Smith and Benoit Dherin and David Barrett and Soham De},
booktitle={International Conference on Learning Representations},
year={2021}
}

@inproceedings{
g.2018gaussian,
title={Gaussian Process Behaviour in Wide Deep Neural Networks},
author={Alexander G. de G. Matthews and Jiri Hron and Mark Rowland and Richard E. Turner and Zoubin Ghahramani},
booktitle={International Conference on Learning Representations},
year={2018}
}

@inproceedings{
barrett2021implicit,
title={Implicit Gradient Regularization},
author={David Barrett and Benoit Dherin},
booktitle={International Conference on Learning Representations},
year={2021}
}

@inproceedings{
wu2018deterministic,
title={Deterministic Variational Inference for Robust {B}ayesian Neural Networks},
author={Anqi Wu and Sebastian Nowozin and Edward Meeds and Richard E. Turner and Jose Miguel Hernandez-Lobato and Alexander L. Gaunt},
booktitle={International Conference on Learning Representations},
year={2019}
}

@InProceedings{pmlr-v139-immer21a,
  title = 	 {Scalable Marginal Likelihood Estimation for Model Selection in Deep Learning},
  author =       {Immer, Alexander and Bauer, Matthias and Fortuin, Vincent and R{\"a}tsch, Gunnar and Emtiyaz, Khan Mohammad},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2021}
}

@article{opper2001learning,
  title={Learning to generalize},
  author={Opper, Manfred},
  journal={Frontiers of Life},
  year={2001}
}

@article{Chatterji2020FinitesampleAO,
  title={Finite-sample analysis of interpolating linear classifiers in the overparameterized regime},
  author={Niladri S. Chatterji and Philip M. Long},
  journal={Journal of Machine Learning Research},
  year={2020}
}

@inproceedings{
sanyal2021how,
title={How Benign is Benign Overfitting ?},
author={Amartya Sanyal and Puneet K. Dokania and Varun Kanade and Philip Torr},
booktitle={International Conference on Learning Representations},
year={2021}
}

@inproceedings{
bubeck2021a,
title={A Universal Law of Robustness via Isoperimetry},
author={Sebastien Bubeck and Mark Sellke},
booktitle={Neural Information Processing Systems},
year={2021}
}

@article{meirzhang,
author = {Meir, Ron and Zhang, Tong},
title = {Generalization Error Bounds for {B}ayesian Mixture Algorithms},
year = {2003},
journal = {Journal of Machine Learning Research}
}

@article{bagging,
author = {Breiman, Leo},
title = {Bagging Predictors},
year = {1996},
journal = {Machine Learning}
}

@inproceedings{boosting,
author = {Freund, Yoav and Schapire, Robert E.},
title = {Experiments with a New Boosting Algorithm},
year = {1996},
booktitle = {International Conference on Machine Learning}
}

@article{grunbaum,
author = {Branko Grünbaum},
title = {Partitions of mass-distributions and of convex bodies by hyperplanes},
journal = {Pacific Journal of Mathematics},
year = {1960}
}

@inproceedings{Boser1992ATA,
  title={A training algorithm for optimal margin classifiers},
  author={Bernhard E. Boser and Isabelle Guyon and Vladimir Naumovich Vapnik},
  booktitle={Conference on Learning Theory},
  year={1992}
}

@book{condorcet, 
title={Essai sur l'Application de l'Analyse à la Probabilité des Décisions Rendues à la Pluralité des Voix}, publisher={Imprimerie Royale}, author={Condorcet, Nicolas de}, year={1785}}

@article{germain,
author = {Germain, Pascal and Lacasse, Alexandre and Laviolette, Fran\c{c}ois and Marchand, Mario and Roy, Jean-Francis},
title = {Risk Bounds for the Majority Vote: From a {PAC-B}ayesian Analysis to a Learning Algorithm},
year = {2015},
journal = {Journal of Machine Learning Research}
}

@inproceedings{masegosaLIS20,
  author={Andrés R. Masegosa and Stephan Sloth Lorenzen and Christian Igel and Yevgeny Seldin},
  title={Second Order {PAC-B}ayesian Bounds for the Weighted Majority Vote},
  year={2020},
  booktitle={Neural Information Processing Systems}
}

@article{boosting2,
author = {Robert E. Schapire and Yoav Freund and Wee Sun Lee and Peter L. Bartlett},
title = {{Boosting the margin: a new explanation for the effectiveness of voting methods}},
journal = {The Annals of Statistics},
year = {1998}
}


@article{poggio,
    author = {Girosi, Federico and Jones, Michael and Poggio, Tomaso},
    title = "Regularization Theory and Neural Networks Architectures",
    journal = {Neural Computation},
    year = {1995}
}

@article{Mobahi2020SelfDistillationAR,
  title={Self-Distillation Amplifies Regularization in Hilbert Space},
  author={Hossein Mobahi and Mehrdad Farajtabar and Peter L. Bartlett},
  journal={ArXiv},
  year={2020},
  volume={abs/2002.05715}
}

@inproceedings{svm-pac-bayes,
 author = {Ambroladze, Amiran and Parrado-Hern\'{a}ndez, Emilio and Shawe-Taylor, John},
 booktitle = {Neural Information Processing Systems},
 title = {Tighter {PAC-B}ayes Bounds},
 year = {2007}
}

@book{arrow,
author = {Arrow, Kenneth J.},
title = {Social Choice and Individual Values},
year = {1951},
publisher = {Wiley}
}

@article{Viallard2021AGF,
  title={A General Framework for the Disintegration of {PAC-B}ayesian Bounds},
  author={Paul Viallard and Pascal Germain and Amaury Habrard and Emilie Morvant},
  journal={arXiv:2102.08649},
  year={2021}
}

@article{rademacher,
author = {Bartlett, Peter L. and Mendelson, Shahar},
title = {Rademacher and {G}aussian Complexities: {R}isk Bounds and Structural Results},
year = {2002},
journal = {Journal of Machine Learning Research},
}

@article{simpson,
    author = {Simpson, Paul B.},
    title = {On Defining Areas of Voter Choice: {P}rofessor {T}ullock on Stable Voting},
    journal = {The Quarterly Journal of Economics},
    year = {1969},
}

@article{Kramer1977ADM,
  title={A dynamical model of political equilibrium},
  author={Gerald H. Kramer},
  journal={Journal of Economic Theory},
  year={1977}
}

@book{Tukey1977ExploratoryDA,
  title={Exploratory Data Analysis},
  author={John W. Tukey},
  publisher={Addison-Wesley},
  year={1977}
}

@article{huber,
author = {Peter J. Huber},
title = {{Projection Pursuit}},
journal = {The Annals of Statistics},
year = {1985}
}

@article{small,
 author = {Christopher G. Small},
 journal = {International Statistical Review},
 title = {A Survey of Multidimensional Medians},
 year = {1990}
}


@article{sixtyfour,
 author = {Andrew Caplin and Barry Nalebuff},
 journal = {Econometrica},
 title = {On 64\%-Majority Rule},
 year = {1988}
}

@article{meanvoter,
 author = {Andrew Caplin and Barry Nalebuff},
 journal = {Econometrica},
 title = {Aggregation and Social Choice: {A} Mean Voter Theorem},
 year = {1991}
}

@inproceedings{lacasse,
 author = {Lacasse, Alexandre and Laviolette, Fran\c{c}ois and Marchand, Mario and Germain, Pascal and Usunier, Nicolas},
 booktitle = {Neural Information Processing Systems},
 title = {{PAC-B}ayes Bounds for the Risk of the Majority Vote and the Variance of the {G}ibbs Classifier},
 year = {2007}
}

@inproceedings{Devroye1996APT,
  title={A Probabilistic Theory of Pattern Recognition},
  author={Luc Devroye and L{\'a}szl{\'o} Gy{\"o}rfi and G{\'a}bor Lugosi},
  booktitle={Stochastic Modelling and Applied Probability},
  year={1996}
}

@article{just-interpolate,
author = {Tengyuan Liang and Alexander Rakhlin},
title = {{Just interpolate: Kernel “ridgeless” regression can generalize}},
journal = {The Annals of Statistics},
year = {2020}
}

@article{make-mistakes,
  title={Interpolating Classifiers Make Few Mistakes},
  author={Tengyuan Liang and Benjamin Recht},
  journal={arXiv:2101.11815},
  year={2021}
}

@InProceedings{pmlr-v119-bordelon20a,
  title = 	 {Spectrum Dependent Learning Curves in Kernel Regression and Wide Neural Networks},
  author =       {Bordelon, Blake and Canatar, Abdulkadir and Pehlevan, Cengiz},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2020}
}


@article{Kanagawa2018GaussianPA,
  title={Gaussian Processes and Kernel Methods: {A} Review on Connections and Equivalences},
  author={Motonobu Kanagawa and Philipp Hennig and Dino Sejdinovic and Bharath K. Sriperumbudur},
  journal={arXiv:1807.02582},
  year={2018}
}

@article {benign,
	author = {Bartlett, Peter L. and Long, Philip M. and Lugosi, G{\'a}bor and Tsigler, Alexander},
	title = {Benign overfitting in linear regression},
	year = {2020},
	journal = {Proceedings of the National Academy of Sciences}
}

@InProceedings{belkin18a,
  title = 	 {To Understand Deep Learning We Need to Understand Kernel Learning},
  author =       {Belkin, Mikhail and Ma, Siyuan and Mandal, Soumik},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2018}
}


@INPROCEEDINGS{separators,
  author={Smith, W.D. and Wormald, N.C.},
  booktitle={Proceedings 39th Annual Symposium on Foundations of Computer Science (Cat. No.98CB36280)}, 
  title={Geometric separator theorems and applications}, 
  year={1998}
}

@ARTICLE{billiards,
  author={Ruján, Pál},
  journal={Neural Computation}, 
  title={Playing Billiards in Version Space}, 
  year={1997}
  }

@inproceedings{bayeskc,
  title={Computing the {B}ayes Kernel Classifier},
  booktitle={Advances in Large-Margin Classifiers},
  author={Ruján, Pál and Marchand, Mario},
  year={2000}
}

@article{bpms,
author = {Herbrich, Ralf and Graepel, Thore and Campbell, Colin},
title = {Bayes Point Machines},
year = {2001},
journal = {Journal of Machine Learning Research}
}

@book{herbrich_book,
author = {Herbrich, Ralf},
title = {Learning Kernel Classifiers: Theory and Algorithms},
year = {2001},
publisher = {MIT Press}
}

@article{watkin,
author = {Watkin, T.},
year = {1993},
title = {Optimal Learning with a Neural Network},
journal = {Europhysics Letters}
}

@article{opperhaussler,
  title = {Generalization performance of {B}ayes optimal classification algorithm for learning a perceptron},
  author = {Opper, Manfred and Haussler, David},
  journal = {Phys. Rev. Lett.},
  year = {1991},
  publisher = {American Physical Society}
}

@article{geiping2021stochastic,
      title={Stochastic Training is Not Necessary for Generalization}, 
      author={Jonas Geiping and Micah Goldblum and Phillip E. Pope and Michael Moeller and Tom Goldstein},
      year={2021},
      journal={arXiv:2109.14119}
}

@article{Biggs2021OnMA,
  title={On Margins and Derandomisation in {PAC-B}ayes},
  author={Felix Biggs and Benjamin Guedj},
  journal={arXiv:2107.03955},
  year={2021}
}

@article{Wu2020DissectingHU,
  title={Dissecting {H}essian: Understanding Common Structure of {H}essian in Neural Networks},
  author={Yikai Wu and Xingyu Zhu and Chenwei Wu and Annie Wang and Rong Ge},
  journal={arXiv:2010.04261},
  year={2020}
}

@article{smd,
  author={Azizan, Navid and Lale, Sahin and Hassibi, Babak},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Stochastic Mirror Descent on Overparameterized Nonlinear Models}, 
  year={2021}
}


@inproceedings{Wilson2017TheMV,
  title={The Marginal Value of Adaptive Gradient Methods in Machine Learning},
  author={Ashia C. Wilson and Rebecca Roelofs and Mitchell Stern and Nathan Srebro and Benjamin Recht},
  booktitle = {Neural Information Processing Systems},
  year={2017}
}

@article{implicit-bias,
  author  = {Daniel Soudry and Elad Hoffer and Mor Shpigel Nacson and Suriya Gunasekar and Nathan Srebro},
  title   = {The Implicit Bias of Gradient Descent on Separable Data},
  journal = {Journal of Machine Learning Research},
  year    = {2018}
}

@book{herbrich,
author = {Herbrich, Ralf},
title = {Learning Kernel Classifiers: Theory and Algorithms},
year = {2001},
publisher = {MIT Press}
}

@inproceedings{
neyshabur2018the,
title={The role of over-parametrization in generalization of neural networks},
author={Behnam Neyshabur and Zhiyuan Li and Srinadh Bhojanapalli and Yann LeCun and Nathan Srebro},
booktitle={International Conference on Learning Representations},
year={2019}
}

@inproceedings{NIPS2002_68d30981,
 author = {Langford, John and Shawe-Taylor, John},
 booktitle = {Neural Information Processing Systems},
 title = {{PAC}-{B}ayes \& Margins},
 year = {2003}
}

@inproceedings{
mehta2021extreme,
title={Extreme Memorization via Scale of Initialization},
author={Harsh Mehta and Ashok Cutkosky and Behnam Neyshabur},
booktitle={International Conference on Learning Representations},
year={2021}
}

@article{Wei2018OnTM,
  title={On the Margin Theory of Feedforward Neural Networks},
  author={Colin Wei and J. Lee and Qiang Liu and Tengyu Ma},
  journal={arXiv:1810.05369},
  year={2018}
}

@inproceedings{neyshabur2018a,
title={A {PAC}-{B}ayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks},
author={Behnam Neyshabur and Srinadh Bhojanapalli and Nathan Srebro},
booktitle={International Conference on Learning Representations},
year={2018}
}

@inproceedings{specnorm,
author = {Bartlett, Peter L. and Foster, Dylan J. and Telgarsky, Matus},
title = {Spectrally-Normalized Margin Bounds for Neural Networks},
year = {2017},
booktitle = {Neural Information Processing Systems}
}

@inproceedings{NEURIPS2018_d465f14a,
 author = {van der Wilk, Mark and Bauer, Matthias and John, ST and Hensman, James},
 booktitle = {Neural Information Processing Systems},
 title = {Learning Invariances using the Marginal Likelihood},
 year = {2018}
}

@inproceedings{
zoph,
title={Neural Architecture Search with Reinforcement Learning},
author={Barret Zoph and Quoc Le},
booktitle={International Conference on Learning Representations},
year={2017}
}

@inproceedings{
liu2018darts,
title={{DARTS}: Differentiable Architecture Search},
author={Hanxiao Liu and Karen Simonyan and Yiming Yang},
booktitle={International Conference on Learning Representations},
year={2019}
}

@inproceedings{NIPS2017_3f5ee243,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L{}ukasz and Polosukhin, Illia},
 booktitle = {Neural Information Processing Systems},
 title = {Attention is All you Need},
 year = {2017}
}



@article{Park2020TowardsNN,
  title={Towards {NNGP}-guided Neural Architecture Search},
  author={Daniel S. Park and Jaehoon Lee and Daiyi Peng and Yuan Cao and Jascha Sohl-Dickstein},
  journal={arXiv:2011.06006},
  year={2020}
}

@article{achille,
author = {Achille, Alessandro and Soatto, Stefano},
title = {Emergence of Invariance and Disentanglement in Deep Representations},
year = {2018},
journal = {Journal of Machine Learning Research}
}

@inproceedings{
foret2021sharpnessaware,
title={Sharpness-aware Minimization for Efficiently Improving Generalization},
author={Pierre Foret and Ariel Kleiner and Hossein Mobahi and Behnam Neyshabur},
booktitle={International Conference on Learning Representations},
year={2021}
}

@inproceedings{
fortuin2021bayesian,
title={Bayesian Neural Network Priors Revisited},
author={Vincent Fortuin and Adri{\`a} Garriga-Alonso and Florian Wenzel and Gunnar Ratsch and Richard E Turner and Mark van der Wilk and Laurence Aitchison},
booktitle={Advances in Approximate Bayesian Inference},
year={2021}
}

@inproceedings{
frankle2018the,
title={The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks},
author={Jonathan Frankle and Michael Carbin},
booktitle={International Conference on Learning Representations},
year={2019}
}

@article{JMLR:v22:20-676,
  author  = {Chris Mingard and Guillermo Valle-P\'erez and Joar Skalse and Ard A. Louis},
  title   = {Is {SGD} a {B}ayesian sampler? {W}ell, almost},
  journal = {Journal of Machine Learning Research},
  year    = {2021}
}

@article{Prez2020GeneralizationBF,
  title={Generalization bounds for deep learning},
  author={Guillermo Valle-P{\'e}rez and Ard A. Louis},
  journal={arXiv:2012.04115},
  year={2020}
}

@inproceedings{McAllester98,
author = {McAllester, David A.},
title = {Some {PAC-B}ayesian Theorems},
year = {1998},
booktitle = {Conference on Computational Learning Theory}
}

@inproceedings{NIPS2017_58191d2a,
 author = {Gunasekar, Suriya and Woodworth, Blake E. and Bhojanapalli, Srinadh and Neyshabur, Behnam and Srebro, Nati},
 booktitle = {Neural Information Processing Systems},
 title = {Implicit Regularization in Matrix Factorization},
 year = {2017}
}

@article{vcpaper,
author = {Vapnik, Vladimir N. and Chervonenkis, Alexey Ya.},
title = {On the Uniform Convergence of Relative Frequencies of Events to Their Probabilities},
journal = {Theory of Probability \& Its Applications},
year = {1971}
}

@book{bishop,
author = {Bishop, Christopher M.},
title = {Pattern Recognition and Machine Learning},
year = {2006},
publisher = {Springer}
}

@inproceedings{Zhang2017UnderstandingDL,
  title={Understanding deep learning requires rethinking generalization},
  author={Chiyuan Zhang and Samy Bengio and Moritz Hardt and Benjamin Recht and Oriol Vinyals},
  year={2017},
  booktitle={International Conference on Learning Representations}
}

@article{Zhang2021WhyFC,
  title={Why Flatness Correlates With Generalization For Deep Neural Networks},
  author={Shuofeng Zhang and Isaac Reid and Guillermo Valle P\'erez and Ard A. Louis},
  journal={arXiv:2103.06219},
  year={2021}
}

@inproceedings{NEURIPS2018_5a4be1fa,
 author = {Jacot, Arthur and Gabriel, Franck and Hongler, Clement},
 booktitle = {Neural Information Processing Systems},
 title = {Neural Tangent Kernel: Convergence and Generalization in Neural Networks},
 year = {2018}
}

@inproceedings{NEURIPS2019_0d1a9651,
 author = {Lee, Jaehoon and Xiao, Lechao and Schoenholz, Samuel and Bahri, Yasaman and Novak, Roman and Sohl-Dickstein, Jascha and Pennington, Jeffrey},
 booktitle = {Neural Information Processing Systems},
 title = {Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient Descent},
 year = {2019}
}

@inproceedings{NEURIPS2019_ae614c55,
 author = {Chizat, L\'{e}na\"{\i}c and Oyallon, Edouard and Bach, Francis},
 booktitle = {Neural Information Processing Systems},
 title = {On Lazy Training in Differentiable Programming},
 year = {2019}
}

@article{seeger,
author = {Seeger, Matthias},
title = {{PAC}-{B}ayesian Generalisation Error Bounds for {G}aussian Process Classification},
year = {2002},
journal = {Journal of Machine Learning Research}
}

@inproceedings{DR17,
        title = {Computing Nonvacuous Generalization Bounds for Deep (Stochastic) Neural Networks with Many More Parameters than Training Data},
       author = {Gintare Karolina Dziugaite and Daniel M. Roy},
         year = {2017},
    booktitle = {Uncertainty in Artificial Intelligence}
}

@article{bic,
author = {Gideon Schwarz},
title = {Estimating the Dimension of a Model},
journal = {The Annals of Statistics},
year = {1978}
}


@article{BLUMER1987377,
title = {Occam's Razor},
journal = {Information Processing Letters},
year = {1987},
author = {Anselm Blumer and Andrzej Ehrenfeucht and David Haussler and Manfred K. Warmuth}
}

@ARTICLE{akaike,
  author={Hirotugu Akaike},
  journal={Automatic Control}, 
  title={A new look at the statistical model identification}, 
  year={1974}}

@inproceedings{ShaweTaylor1996AFF,
  title={A framework for structural risk minimisation},
  author={John Shawe-Taylor and Peter L. Bartlett and Robert C. Williamson and Martin Anthony},
  booktitle={Conference on Learning Theory},
  year={1996}
}

@inproceedings{Hinton1993KeepingTN,
  title={Keeping neural networks simple by minimizing the description length of the weights},
  author={Geoffrey E. Hinton and Drew van Camp},
  booktitle={Conference on Learning Theory},
  year={1993}
}

@article{SCHMIDHUBER1997857,
title = {Discovering Neural Nets with Low {K}olmogorov Complexity and High Generalization Capability},
journal = {Neural Networks},
year = {1997},
author = {Jürgen Schmidhuber},
}

@InProceedings{pmlr-v70-arpit17a, title = {A Closer Look at Memorization in Deep Networks}, author = {Devansh Arpit and Stanis{\l}aw Jastrz{\k{e}}bski and Nicolas Ballas and David Krueger and Emmanuel Bengio and Maxinder S. Kanwal and Tegan Maharaj and Asja Fischer and Aaron Courville and Yoshua Bengio and Simon Lacoste-Julien}, booktitle = {International Conference on Machine Learning},
year=2017}

@article{Dingle2018InputoutputMA,
  title={Input–output maps are strongly biased towards simple outputs},
  author={Kamaludin Dingle and Chico Q. Camargo and Ard A. Louis },
  journal={Nature Communications},
  year={2018}
}

@inproceedings{NEURIPS2019_feab05aa,
 author = {De Palma, Giacomo and Kiani, Bobak and Lloyd, Seth},
 booktitle = {Neural Information Processing Systems},
 title = {Random deep neural networks are biased towards simple functions},
 year = {2019}
}

@inproceedings{ShaweTaylor1997APA,
  title={A {PAC} analysis of a {B}ayesian estimator},
  author={John Shawe-Taylor and Robert C. Williamson},
  booktitle={Conference on Learning Theory},
  year={1997}
}

@article{rissanen1986,
author = "Rissanen, Jorma",
journal = "Annals of Statistics",
title = "Stochastic Complexity and Modeling",
year = "1986"
}


@misc{lecun2010mnist,
  title={{MNIST} handwritten digit database},
  author={LeCun, Yann and Cortes, Corinna and Burges, Christopher J.C.},
  year={1998}
}

@misc{genomic,
title={Encoding innate ability through a genomic bottleneck},
author={Alexei Koulakov and Sergey Shuvaev and Anthony Zador},
note={Personal communication},
year={2021}
}

@inproceedings{Shah2020ThePO,
 author = {Shah, Harshay and Tamuly, Kaustav and Raghunathan, Aditi and Jain, Prateek and Netrapalli, Praneeth},
 booktitle = {Neural Information Processing Systems},
 title = {The Pitfalls of Simplicity Bias in Neural Networks},
 year = {2020}
}

@book{Genz2009ComputationOM,
  title={Computation of Multivariate Normal and t Probabilities},
  author={Alan Genz and Frank Bretz},
  publisher={Springer},
  year={2009}
}

@inproceedings{finvinfin,
title={Finite Versus Infinite Neural Networks: an Empirical Study},
author={Jaehoon Lee and Sam Schoenholz and Jeffrey Pennington and Ben Adlam and Lechao Xiao and Roman Novak and Jascha Sohl-Dickstein},
booktitle={Neural Information Processing Systems},
year={2020}
}

@inproceedings{
lee2018deep,
title={Deep Neural Networks as {G}aussian Processes},
author={Jaehoon Lee and Jascha Sohl-Dickstein and Jeffrey Pennington and Roman Novak and Sam Schoenholz and Yasaman Bahri},
booktitle={International Conference on Learning Representations},
year={2018}
}

@book{vaart_1998, place={Cambridge}, title={Asymptotic Statistics}, publisher={Cambridge University Press}, author={Aad W. van der Vaart}, year={1998}}

@inproceedings{stan,
 author = {Fort, Stanislav and Jastrzebski, Stanislaw},
 booktitle = {Neural Information Processing Systems},
 title = {Large Scale Structure of Neural Network Loss Landscapes},
 year = {2019}
}

@inproceedings{
li2018measuring,
title={Measuring the Intrinsic Dimension of Objective Landscapes},
author={Chunyuan Li and Heerad Farkhoor and Rosanne Liu and Jason Yosinski},
booktitle={International Conference on Learning Representations},
year={2018}
}


@InProceedings{pmlr-v9-glorot10a, title = {Understanding the difficulty of training deep feedforward neural networks}, author = {Xavier Glorot and Yoshua Bengio}, booktitle = {Artificial Intelligence and Statistics}, year = {2010} }

@techreport{Langford01boundsfor,
    author = {John Langford and Matthias Seeger},
    title = {Bounds for averaging classifiers},
    type={Technical report},
    institution = "Carnegie Mellon University",
    year = {2001}
}

@inproceedings{denker,
 author = {Denker, John and Wittner, Ben},
 booktitle = {Neural Information Processing Systems},
 title = {Network Generality, Training Required, and Precision Required},
 year = {1988}
}

@article{Bialek2001PredictabilityCA,
  title={Predictability, Complexity, and Learning},
  author={W. Bialek and Ilya Nemenman and Naftali Tishby},
  journal={Neural Computation},
  year={2001}
}

@article{Daniels2012SparseCO,
  title={Sparse code of conflict in a primate society},
  author={B. C. Daniels and D. C. Krakauer and J. Flack},
  journal={Proceedings of the National Academy of Sciences},
  year={2012}
}

@article{Biederman1987RecognitionbycomponentsAT,
  title={Recognition-by-components: {A} theory of human image understanding},
  author={I. Biederman},
  journal={Psychological review},
  year={1987}
}

@article{Haun2017AreWU,
  title={Are we underestimating the richness of visual experience?},
  author={Andrew M. Haun and G. Tononi and C. Koch and Naotsugu Tsuchiya},
  journal={Neuroscience of Consciousness},
  year={2017}
}

@article{landauer,
title = "How much do people remember? {S}ome estimates of the quantity of learned information in long-term memory",
journal = "Cognitive Science",
year = "1986",
author = "Thomas K. Landauer",
}

@article{Mollica2019HumansSA,
  title={Humans store about 1.5 megabytes of information during language acquisition},
  author={Frank Mollica and Steven Piantadosi},
  journal={Royal Society Open Science},
  year={2019}
}

@article{nanoconnectomic,
article_type = {journal},
title = {Nanoconnectomic upper bound on the variability of synaptic plasticity},
author = {Thomas M. {Bartol Jr.} and Bromer, Cailey and Kinney, Justin and Chirillo, Michael A. and Bourne, Jennifer N. and Harris, Kristen M. and Sejnowski, Terrence J.},
year = 2015,
journal = {eLife}
}

@article{linial,
title = "Results on learnability and the {V}apnik-{C}hervonenkis dimension",
author = "Nathan Linial and Yishay Mansour and Ronald L. Rivest",
journal = "Information and Computation",
year = "1991"
}

@inproceedings{
valle-perez2018deep,
title={Deep learning generalizes because the parameter--function map is biased towards simple functions},
author={Guillermo Valle-P{\'e}rez and Chico Q. Camargo and Ard A. Louis},
booktitle={International Conference on Learning Representations},
year={2019}
}

@phdthesis{radford,
  author       = {Radford M. Neal}, 
  title        = {Bayesian Learning for Neural Networks},
  school       = {Department of Computer Science, University of Toronto},
  year         = 1994,
  type     = {{Ph.D.} thesis}
}

@article{Ulyanov2018DeepIP,
  title={Deep Image Prior},
  author={Dmitry Ulyanov and Andrea Vedaldi and Victor Lempitsky},
  journal={Computer Vision and Pattern Recognition},
  year={2018}
}

@article{
cooper2019the,
title={The loss landscape of overparameterized neural networks},
author={Yaim Cooper},
year={2019},
journal={arXiv:1804.10200}
}

@inproceedings{
sun2022mirror,
title={Mirror Descent Maximizes Generalized Margin and Can Be Implemented Efficiently},
author={Haoyuan Sun and Kwangjun Ahn and Christos Thrampoulidis and Navid Azizan},
booktitle={Neural Information Processing Systems},
year={2022}
}

@article{bregman1967relaxation,
  title={The relaxation method of finding the common point of convex sets and its application to the solution of problems in convex programming},
  author={Bregman, Lev M.},
  journal={USSR Computational Mathematics and Mathematical Physics},
  year={1967}
}

@inproceedings{azizan2019stochastic,
  title={A Stochastic Interpretation of Stochastic Mirror Descent: Risk-Sensitive Optimality},
  author={Azizan, Navid and Hassibi, Babak},
  booktitle={Conference on Decision and Control},
  year={2019}
}

%%%%%%%%%%%%%%%%%%%
%%%% My pubs
%%%%%%%%%%%%%%%%%%%

@unpublished{my-spectral, title={Hyperparameter transfer via spectrally controlled weight updates}, author={Jeremy Bernstein and James B. Simon and Greg Yang}, year={2022},
note ={In preparation.}}

@inproceedings{my-margin, title = {Investigating generalization by controlling normalized margin}, author = {Alexander R. Farhang and Jeremy Bernstein and Kushal Tirumala and Yang Liu and Yisong Yue}, booktitle = {International Conference on Machine Learning}, year = {2022}}


@inproceedings{my-fromage, title={On the distance between two neural networks and the stability of learning}, author={Jeremy Bernstein and Arash Vahdat and Yisong Yue and Ming-Yu Liu}, booktitle = {Neural Information Processing Systems}, year={2020}}
 
@inproceedings{my-madam, title={Learning compositional functions via multiplicative weight updates}, author={Jeremy Bernstein and Jiawei Zhao and Markus Meister and Ming-Yu Liu and Anima Anandkumar and Yisong Yue}, booktitle = {Neural Information Processing Systems}, year={2020}}

@inproceedings{my-nero, title = {Learning by turning: {N}eural architecture aware optimisation}, author = {Yang Liu and Jeremy Bernstein and Markus Meister and Yisong Yue}, booktitle = {International Conference on Machine Learning}, year = {2021}}

@unpublished{my-bpm, title={Max-margin neural networks as {B}ayes point machines}, author={Jeremy Bernstein and Alexander R. Farhang and Yisong Yue}, year={2022}, note ={In preparation.}}

@unpublished{my-mm, title={Majorise-minimise for deep networks via architectural perturbation bounds}, author={Kevin Huang and Chris Mingard and Yisong Yue and Jeremy Bernstein}, year={2022}, note ={In preparation.}}